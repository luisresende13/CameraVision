# -*- coding: utf-8 -*-
"""cameras_schedule

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EqyaJCxbDv3OgI94zaPcjrpnVIQNDWmT

### Clone flask api repository
"""

# !git clone --branch my-branch https://github.com/luisresende13/CameraVision

"""### Change directory before installing dependencies"""

import os
os.chdir("../")

"""### Install requirements"""

# !pip install -r requirements.txt

"""### Parse command-line arguments"""

def parse_arguments():
    parser = argparse.ArgumentParser(description='CameraVision cameras schedule python script')
    
    # parser.add_argument('--aws_access_key', type=str, default='', help='AWS Access Key ID')
    # parser.add_argument('--aws_secret_key', type=str, default='', help='AWS Secret Access Key')
    # parser.add_argument('--aws_region', type=str, default='', help='AWS Default Region')
    parser.add_argument('--n_random', type=int, default=1, help='Number of random cameras for inference')
    parser.add_argument('--allow_replacement', action='store_true', help='Allow replacement of cameras in random selection')
    parser.add_argument('--use_parallel', action='store_true', help='Use parallel execution with threads')
    parser.add_argument('--yolo_minutes', type=float, default=0.3334, help='Frequency of running the YOLO inference in minutes')
    parser.add_argument('--max_retries', type=int, default=1, help='Maximum number of retries for failed requests')
    parser.add_argument('--backoff_factor', type=float, default=1, help='Backoff factor for retries')
    parser.add_argument('--retry_codes', type=int, nargs='+', default=[500], help='HTTP status codes to retry')
    parser.add_argument('--raise_on_status', action='store_true', help='Raise exception on non-2xx status codes')
    
    args = parser.parse_args()
    return args

"""### Function to request parallel inference for cameras in database"""

import time
import datetime
import pytz
import urllib
import requests
import json
import numpy as np
from requests_futures.sessions import FuturesSession
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import torch

# Check if a GPU is available
if torch.cuda.is_available():
    # Set the default GPU (index 0 in this example)
    torch.cuda.set_device(0)
    
# Set the timezone to Brazil
timezone = pytz.timezone("America/Sao_Paulo")

source_fields_names = {
    "id": "camera_id",
    "url": "source",
}

def cameras_inference(
    base_url='https://octa-vision-oayt5ztuxq-ue.a.run.app',
    query={},
    n_random=1,
    allow_replacement=False,
    source_field="id",
    seconds=None,
    execution_seconds=None,
    params={},
    max_retries=1,
    backoff_factor=1,
    retry_codes=[500],
    raise_on_status=False,
    show_params=True,
    use_parallel=True,
):

    # Cameras request start
    start_time = time.time()
    start = datetime.datetime.now(timezone).strftime("%Y-%m-%d %H:%M:%S %Z")
    print("\nStart Time (Brazil):", start)

    # Start async session
    session = FuturesSession()

    # Retry configuration
    if max_retries > 1:
        retry_strategy = Retry(
            total=max_retries,
            backoff_factor=backoff_factor,
            status_forcelist=retry_codes,
            raise_on_status=raise_on_status,
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount(base_url, adapter)

    # Get cameras from database
    try:
        # res = requests.get(f'{base_url}/cameras')
        res = session.get(f'{base_url}/cameras').result()
        if res.ok:
            cameras = res.json()
        else:
            raise Exception(f'Code {res.status_code}, {res.reason}')
    except Exception as e:
        print(f'\nGET /cameras FAILED: {e}')
        cameras = []

    # Report /camera success
    if len(cameras):
        cameras_time = round(time.time() - start_time, 2)
        print(f'\nGET /cameras SUCCESS. EXECUTION-TIME: {cameras_time} s\n')

    if query:
        # Format query dict argument
        query = {key: value if type(value) is list else [value] for key, value in query.items()}

        # Query cameras based on attribute values
        cameras = [camera for camera in cameras if any([any([value in camera[key] for value in values]) for key, values in query.items()])]

    # Random sample with size `n_random`
    if n_random is not None and len(cameras):
        cameras = np.random.choice(cameras, size=n_random, replace=allow_replacement)

    # Delete items with `None` value
    # del_keys = []
    # for key in params:
    #     if params[key] is None:
    #         del_keys.append(key)
    # for key in del_keys:
    #     del params[key]

    # Override `seconds` query parameter
    if seconds is not None:
        params['seconds'] = seconds
    elif execution_seconds is not None:
        params['execution_seconds'] = execution_seconds

    # Build requests url and params
    params_list = []
    for camera in cameras:
        params[source_fields_names[source_field]] = camera[source_field] # camera id or source fields
        # params["dt"] = str(int(np.random.random() * 1e9))
        params_list.append(params.copy())

    # Report requests start
    inference_start_time = time.time()

    # Display list of request parameters
    if show_params:
        print("\nREQUEST LIST:", json.dumps(params_list, indent=4), '\n')

    if use_parallel:
        # Use parallel execution with threads
        executor = ThreadPoolExecutor(max_workers=len(cameras))
    else:
        # Use parallel execution with processes
        executor = ProcessPoolExecutor(max_workers=len(cameras))

    futures = [executor.submit(yolo_watch_camera_sync, args) for args in params_list]

    # Get the actual results from the completed tasks
    results = []
    for index, future in enumerate(as_completed(futures)):
        # Wait for process to finish
        result = future.result()
        results.append(result)

        # Report progress
        elapsed_time = round(time.time() - inference_start_time, 2)
        result_example = str(result)[:160]
        if isinstance(result, list):
            result_example = len(result)
        print(f'   Camera {index + 1}/{len(futures)} · Elapsed-Time: {elapsed_time} s · Response: {result_example}')

    # Clean up the executor manually
    executor.shutdown()

    inference_elapsed_time = round(time.time() - inference_start_time, 2)
    total_elapsed_time = round(time.time() - start_time, 2)
    end = datetime.datetime.now(timezone).strftime("%Y-%m-%d %H:%M:%S %Z")

    print(f"\n* DONE! · CAMERAS: {len(params_list)} · REQUESTED-SECONDS: {seconds} s · REQUESTED-EXECUTION-SECONDS: {execution_seconds} s · INFERENCE-SECONDS: {inference_elapsed_time} · TOTAL-SECONDS: {total_elapsed_time} s")
    print("\nEnd Time (Brazil):", end, '\n')

    return results

"""### Environment settings"""

# import os

# os.environ['AWS_ACCESS_KEY_ID'] = ''
# os.environ['AWS_SECRET_ACCESS_KEY'] = ''
# os.environ['AWS_DEFAULT_REGION'] = ''

from modules.aws import EC2Instance
from modules.yolo_util import yolo_watch_camera

def yolo_watch_camera_sync(kwargs):
    results = yolo_watch_camera(**kwargs)
    return list(results)

ec2 = EC2Instance(test=True)

"""### Scheduler settings"""

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import time

# Set jobs
# main_job = yolo_job


# Set job frequency
yolo_minutes = 1.0
yolo_seconds = int(yolo_minutes * 60)

# Schedule the job to run every 30 seconds, starting at 00:00 hours
if yolo_minutes < 1.0:
    yolo_trigger = CronTrigger(second=f'*/{yolo_seconds}')
else:
    yolo_trigger = CronTrigger(minute=f'*/{int(yolo_minutes)}')

print('\nJOB FREQUENCY:', yolo_seconds, 's\n')

"""## Scheduler Main Job

#### Function usage - Run inference for cameras in parallel
"""

params = {
    'task': 'track',
    'device': 'cpu',
    'capture': 'opencv',
    'process': 'bigquery',
    'model': 'yolov8n.pt',
    'retries': 1,
    'retry_delay': 1.0,
    'log_seconds': None,
}

responses_list = []

def main_job():
    responses = cameras_inference(
        base_url=ec2.url,
        query={"name": ["#1"]}, #, "#2", "#3", '#4', '#5']},
        n_random=None,
        allow_replacement=False,
        source_field="id",
        # seconds=yolo_seconds,
        execution_seconds=yolo_seconds - 10,
        params=params,
        max_retries=1,
        backoff_factor=0.2,
        retry_codes=[500],
        raise_on_status=False,
        show_params=False,
        use_parallel=True
    )

    # Gather responses
    responses_list.append(responses)


# ---
# Example usage

# main_job()

"""#### Show list of responses"""

print('responses_list:', responses_list)

"""## Scheduler execution"""

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.executors.pool import ProcessPoolExecutor as PPE
import time
import datetime
import pytz

# Set the timezone to Brazil
timezone = pytz.timezone("America/Sao_Paulo")

# Set process type
process_type = "threads" # 

# Set maximum runnng instances
max_running_instances = 8

if process_type == 'process':
    # Create a ProcessPoolExecutor instance
    process_executor = PPE(max_workers=max_running_instances)

    # Create a BackgroundScheduler instance with the process executor
    sched = BackgroundScheduler(executors={'processpool': process_executor})

elif process_type == 'threads':
    # Create a BackgroundScheduler instance
    sched = BackgroundScheduler()

# Start the scheduler
sched.start()

# Schedule the main_job to run at the desired frequency
sched.add_job(main_job, yolo_trigger, max_instances=max_running_instances)

try:
    # Report scheduler start
    print("* SCHEDULER STARTED (Brazil):", datetime.datetime.now(timezone).strftime('%Y-%m-%d %H:%M:%S %Z'), '\n\n')
    # Keep the script running (blocked) to allow the scheduled jobs to execute
    while True:
        time.sleep(1)
except (KeyboardInterrupt, SystemExit):
    # Stop the scheduler gracefully on keyboard interrupt
    sched.shutdown()
    print("\n* SCHEDULER STOPPED.")

"""### Run schedule in the background as python script"""

# !nohup python sched.py
# !python cameras_sched.py